<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Kangfu MEI's Homepage</title>

  <meta name="author" content="Kangfu MEI">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="preconnect" href="https://fonts.googleapis.com"> 
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
  <link href="https://fonts.googleapis.com/css2?family=Ma+Shan+Zheng&display=swap" rel="stylesheet">
  <style>
    /*Google logo colors*/
    .g-blue{ color:#4285F4; }
    .o-red{ color:#DB4437; }
    .o-yellow{ color:#F4B400; }
    .l-green{ color:#0F9D58; }
    .e-red { display:inline-block;transform:rotate(-20deg); }
    hr.solid {
      border-top: 3px solid #bbb;
    }
    .content {
      width: 100%;
      height: 100%;
    }

    .content .header {
      height: 50px;
      position: sticky;
      top: 0;
      background-color: white;
      z-index: 100;
    }
    .content-inner {
      top: -1;
    }
  </style>
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Kangfu MEI <span style="font-family: 'Ma Shan Zheng', cursive;">梅 康夫</span></name>
                  </p>
                  <p>I am a third-year Ph.D. student (2021 - 2025*) at <a href="hhttps://www.jhu.edu"> Johns Hopkins University </a>, advised by <a href="https://engineering.jhu.edu/vpatel36/sciencex_teams/vishalpatel/"> Prof. Vishal Patel </a>, where I work on compute vision and computational photography.
                    I got my M.Phil degree (2019 - 2021) at <a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a>, advised by <a href="https://myweb.cuhk.edu.cn/ruihuang"> Prof. Rui Huang</a>.
                  </p>
                  <!-- <p style="font-size: larger;color: crimson;">I am open to full-time job opportunities starting early in 2025.</p> -->
                  <p>
                    I am a Research Intern at <span class="g-blue">G</span><span
                    class="o-red">o</span><span class="o-yellow">o</span><span class="g-blue">g</span><span
                    class="l-green">l</span><span class="o-red e-red">e</span></span> Research (<i>Jun 2023 - Now</i>).
                  </p>
                  <p>
                    I previously interned at: <a href="https://research.adobe.com">Adobe Research <img src="https://img.icons8.com/external-those-icons-lineal-color-those-icons/24/null/external-Adobe-logos-and-brands-those-icons-lineal-color-those-icons.png"/></a> &nbsp/&nbsp
                    <a href="https://damo.alibaba.com/?lang=en">DAMO Academy</a> <img src="https://img.icons8.com/color/24/null/taobao.png"/> &nbsp/&nbsp
                    <a href="http://www.kwai.com/aboutus">Kuaishou</a> <img src="https://img.icons8.com/external-regular-kawalan-studio/24/ff5000/external-kwai-social-media-regular-kawalan-studio.png"/> &nbsp/&nbsp
                    <a href="https://www.jddglobal.com/en/">JD.COM</a>
                  </p>
                  <p style="text-align:center">
                    <a href="https://kfmei.page/data/Kangfu_CV.pdf">CV</a> &nbsp/&nbsp
                    <a href="mailto:mikumkf@gmail.com">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=e_nu_TIAAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/MKFMIKU">Github</a> &nbsp/&nbsp
                    <a href="https://photography.kfmei.page"><span class="highlight">Photography</span></a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/Kangfu.jpg"><img style="width:80%;max-width:80%;" alt="profile photo"
                      src="images/Kangfu.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    I have a strong interest in image, video, and 3D genetation.
                    Representative papers are <span class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody class="content">
              <tr  class="header">
                <td style="padding-left:20px; padding-top: 10px;width: 25%;">
                  <heading>2024</heading>
                  <hr class="solid">
                </td>
                <td style="width: 75%;"></td>
              </tr>

              <tr onmouseout="sdft_stop()" onmouseover="sdft_start()" class="content-inner" bgcolor="#ffffd0">
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='sdft_image'>
                      <video src='images/sdft_before.mp4' width="160" autoplay loop>
                    </div>
                    <video src='images/sdft_after.mp4' width="160" autoplay loop>
                  </div>
                  <script type="text/javascript">
                    function sdft_start() {
                      document.getElementById('sdft_image').style.opacity = "1";
                    }

                    function sdft_stop() {
                      document.getElementById('sdft_image').style.opacity = "0";
                    }
                    sdft_stop()
                  </script>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a href="sdft/">
                    <papertitle>sDFT: Scaling Diffusion Field Transformers on Images, Videos, and 3D Data</papertitle>
                  </a>
                  <br>
                  <span class="author-block">
                    <strong>Kangfu Mei</strong>,
                  </span>
                  <span class="author-block">
                    <a href="https://cdluminate.github.io/">Mo Zhou</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://engineering.jhu.edu/vpatel36/team/vishalpatel/">Vishal M. Patel</a>,
                  </span>
                  <br>
                  <em>Work in Progress</em>
                  <br>
                  <a href="sdft/sdft-draft.pdf">PDF</a> /
                  <a href="sdft/">project page</a>
                  <p></p>
                  <p>A generative filed model that can generate image, video, and 3D data in a single unified network architecture. The unification can boost video generation with 3D prior in multi-task learning, with the 10 times smaller model size than SORA.</p>
                </td>
              </tr>
            
  
              <tr onmouseout="bid_stop()" onmouseover="bid_start()" class="content-inner">
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/scaling.png' width="160">
                  </div>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2404.01367">
                    <papertitle>Bigger is not Always Better: Scaling Properties of Latent Diffusion Models</papertitle>
                  </a>
                  <br>
                  <span class="author-block">
                    <strong>Kangfu Mei</strong>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/zhengzhong-tu-92419790/">Zhengzhong Tu</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://mdelbra.github.io">Mauricio Delbracio</a></span>,
                  <span class="author-block">
                    <a href="https://research.google/people/hossein-talebi/">Hossein Talebi</a></sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://engineering.jhu.edu/vpatel36/team/vishalpatel/">Vishal M. Patel</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://sites.google.com/view/milanfarhome/">Peyman Milanfar</a>
                  </span>
                  <br>
                  <em>arXiv 2024</em>
                  <br>
                  <!-- <a href="bi-noising">Project Page</a> / -->
                  <a href="https://arxiv.org/abs/2404.01367">arXiv</a>
                  <p></p>
                  <p>The first work that throughly investigates the scaling properties of the recent trending latent diffsuion models (e.g., the representative StableDiffusion).</p>
                </td>
              </tr>

              <tr class="header">
                <td style="padding-left:20px; padding-top: 10px;">
                  <heading>2023</heading>
                  <hr class="solid">
                </td>
                <td style="width: 75%;"></td>
              </tr>

                            
              <tr bgcolor="#ffffd0" class="content-inner">
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/codi.jpg' width="160">
                  </div>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a href="https://fast-codi.github.io/">
                    <papertitle>CoDi: Conditional Diffusion Distillation for Higher-Fidelity and Faster Image Generation</papertitle>
                  </a>
                  <br>
                  <span class="author-block">
                    <strong>Kangfu Mei</strong>,
                  </span>
                  <span class="author-block">
                    <a href="https://mdelbra.github.io">Mauricio Delbracio</a></span>,
                  <span class="author-block">
                    <a href="https://research.google/people/hossein-talebi/">Hossein Talebi</a></sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/zhengzhong-tu-92419790/">Zhengzhong Tu</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://engineering.jhu.edu/vpatel36/team/vishalpatel/">Vishal M. Patel</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://sites.google.com/view/milanfarhome/">Peyman Milanfar</a>
                  </span>
                  <br>
                  
                  <em>CVPR 2024</em>
                  <br>
                  <a href="https://fast-codi.github.io/">project page</a> /
                  <a href="https://arxiv.org/abs/2310.01407">arXiv</a>
                  <p></p>
                  <p>Faster conditional diffusion that produces high-quality images with 1-4 sampling steps.</p>
                </td>
              </tr>

              <tr onmouseout="vidm_stop()" onmouseover="vidm_start()" bgcolor="#ffffd0">
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='vidm_image'>
                      <img src='vidm/results/taichi/vidm.gif' width="160">
                    </div>
                    <img src='vidm/results/sky/vidm.gif' width="160">
                  </div>
                  <script type="text/javascript">
                    function vidm_start() {
                      document.getElementById('vidm_image').style.opacity = "1";
                    }

                    function vidm_stop() {
                      document.getElementById('vidm_image').style.opacity = "0";
                    }
                    vidm_stop()
                  </script>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a href="vidm/">
                    <papertitle>VIDM: Video Implicit Diffusion Models</papertitle>
                  </a>
                  <br>
                  <strong>Kangfu Mei</strong>,
                  <a href="https://engineering.jhu.edu/vpatel36/sciencex_teams/vishalpatel/">Vishal M. Patel</a>,
                  <br>
                  <em>AAAI</em>, 2023 <span style="padding-left:.1rem; padding-right:.1rem; background-color: #FBCBCB; color: #e34234;"><i><b>Oral Presentation</b></i></span>
                  <br>
                  <a href="vidm/">project page</a> /
                  <a href="https://arxiv.org/abs/2212.00235">arXiv</a>
                  <p></p>
                  <p>Video Generation Diffusion Models By Using Implicit Motiion Condition.</p>
                </td>
              </tr>

              <tr class="header">
                <td style="padding-left:20px; padding-top: 10px;">
                  <heading>2022</heading>
                  <hr class="solid">
                </td>
                <td style="width: 75%;"></td>
              </tr>

              <tr onmouseout="d2sm_stop()" onmouseover="d2sm_start()" bgcolor="#ffffd0">
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='d2sm_image'>
                      <img src='images/d2sm_after.png' width="160">
                    </div>
                    <img src='images/d2sm_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function d2sm_start() {
                      document.getElementById('d2sm_image').style.opacity = "1";
                    }

                    function d2sm_stop() {
                      document.getElementById('d2sm_image').style.opacity = "0";
                    }
                    d2sm_stop()
                  </script>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a href="d2sm">
                    <papertitle>Deep Semantic Statistics Matching (D2SM) Denoising Network</papertitle>
                  </a>
                  <br>
                  <strong>Kangfu Mei</strong>,
                  <a href="https://engineering.jhu.edu/vpatel36/sciencex_teams/vishalpatel/">Vishal M. Patel</a>,
                  <a href="https://myweb.cuhk.edu.cn/ruihuang">Rui Huang</a>
                  <br>
                  <em>ECCV</em>, 2022
                  <br>
                  <a href="d2sm">project page</a> /
                  <a href="https://arxiv.org/abs/2207.09302">arXiv</a> / 
                  <a href="d2sm/d2sm-poster.pdf">poster</a>
                  <p></p>
                  <p>A New General Plug-and-play Component For Denoising</p>
                </td>
              </tr>

              <tr onmouseout="shadow_stop()" onmouseover="shadow_start()">
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='shadow_image'>
                      <img src='images/shadow_after.png' width="160">
                    </div>
                    <img src='images/shadow_before.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function shadow_start() {
                      document.getElementById('shadow_image').style.opacity = "1";
                    }

                    function shadow_stop() {
                      document.getElementById('shadow_image').style.opacity = "0";
                    }
                    shadow_stop()
                  </script>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a
                    href="shadow-diffusion/">
                    <papertitle>Latent Feature-Guided Diffusion Models for Shadow Removal</papertitle>
                  </a>
                  <br>
                  <strong>Kangfu Mei</strong>, Luis Figueroa, Zhe Lin, Zhihong Ding, Scott Cohen,
                  <a href="https://engineering.jhu.edu/vpatel36/sciencex_teams/vishalpatel/">Vishal M. Patel</a>
                  <br>
                  <em>WACV</em>, 2023
                  <br>
                  <a href="shadow-diffusion/">project page</a> /
                  <a href="https://github.com/MKFMIKU/Instance-Shadow-Diffusion">code</a> /
                  <a href="https://huggingface.co/spaces/MKFMIKU/Instance-Shadow-Removal">demo</a> /
                  <a href="https://arxiv.org/abs/2312.02156">arXiv</a>
                  <p></p>
                  <p>We (together with Adobe) conducted this very early exploration of applying diffusion models on shadow removal. This proposes the first instance-level shadow removal task.</p>
                </td>
              </tr>

              <tr class="header">
                <td style="padding-left:20px; padding-top: 10px;">
                  <heading>2021</heading>
                  <hr class="solid">
                </td>
                <td style="width: 75%;"></td>
              </tr>

                            
              <tr>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/lttgan.jpg' width="160">
                  </div>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2112.02379">
                    <papertitle>LTT-GAN: Looking Through Turbulence by Inverting GANs</papertitle>
                  </a>
                  <br>
                  <strong>Kangfu Mei</strong>,
                  <a href="https://engineering.jhu.edu/vpatel36/sciencex_teams/vishalpatel/">Vishal M. Patel</a>
                  <br>
                  <em>IEEE Journal of Selected Topics in Signal Processing</em> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4200690"><i style="color: gray; font-size: .6rem;">[IF: 7.695]</i></a>
                  <br>
                  <!-- <a href="https://kfmei.page/LTT-GAN/">Project Page</a> / -->
                  <a href="https://arxiv.org/abs/2112.02379">arXiv</a>
                  <p></p>
                  <p>The first turbulence mitigation algorithm that can clearly recover face images captured in a range of 300 meters long.</p>
                </td>
              </tr>

              <tr>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/attanet.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function dpl_start() {
                      document.getElementById('dpl_image').style.opacity = "1";
                    }

                    function dpl_stop() {
                      document.getElementById('dpl_image').style.opacity = "0";
                    }
                    dpl_stop()
                  </script>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a href="https://songqi-github.github.io/research/AttaNet/index.html">
                    <papertitle>AttaNet: Attention-Augmented Network for Fast and Accurate Scene Parsing</papertitle>
                  </a>
                  <br>
                  Qi Song, <strong>Kangfu Mei</strong>,
                  <a href="https://myweb.cuhk.edu.cn/ruihuang">Rui Huang</a>
                  <br>
                  <em>AAAI</em>, 2021
                  <br>
                  <a href="https://github.com/songqi-github/AttaNet">code</a> /
                  <a href="https://arxiv.org/abs/2103.05930">arXiv</a>
                  <p></p>
                  <p>Strip Attention Module (SAM) and Attention Fusion Module (AFM) are proposed for enhancing
                    the accuracy of semantic segmentation networks with limited computational complexity.</p>
                </td>
              </tr>

              <tr class="header">
                <td style="padding-left:20px; padding-top: 10px;width:25%vertical-align:middle">
                  <heading>2019</heading>
                  <hr class="solid">
                </td>
                <td style="width: 75%;"></td>
              </tr>

              <tr onmouseout="hern_stop()" onmouseover="hern_start()">
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='hern_image'>
                      <img src='images/hern_after.jpg' width="160">
                    </div>
                    <img src='images/hern_before.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function hern_start() {
                      document.getElementById('hern_image').style.opacity = "1";
                    }

                    function hern_stop() {
                      document.getElementById('hern_image').style.opacity = "0";
                    }
                    hern_stop()
                  </script>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a
                    href="https://arxiv.org/abs/1911.08098">
                    <papertitle>Higher-resolution network for image demosaicing and enhancing</papertitle>
                  </a>
                  <br>
                  <strong>Kangfu Mei</strong>, <a href="https://junchenglee.com/">Juncheng Li</a>, Jiajie Zhang, Haoyu Wu, Jie Li, Rui Huang
                  <br>
                  <em>ICCV AIM RAW to RGB mapping challenge</em>, 2019
                  <br>
                  <a href="https://github.com/MKFMIKU/RAW2RGBNet">code</a> /
                  <a href="https://arxiv.org/abs/1911.08098">arXiv</a>
                  <p></p>
                  <p>For the first time, a neural ISP has outperformed a traditional ISP (like Huawei's mobile ISP) and achieved visual quality comparable to that of a DSLR.</p>
                </td>
              </tr>

              <tr onmouseout="pffnet_stop()" onmouseover="pffnet_start()">
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='pffnet_image'>
                      <img src='images/pffnet_after.png' width="160">
                    </div>
                    <img src='images/pffnet_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function pffnet_start() {
                      document.getElementById('pffnet_image').style.opacity = "1";
                    }

                    function pffnet_stop() {
                      document.getElementById('pffnet_image').style.opacity = "0";
                    }
                    pffnet_stop()
                  </script>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a
                    href="https://arxiv.org/abs/1810.02283">
                    <papertitle>Progressive Feature Fusion Network for Realistic Image Dehazing</papertitle>
                  </a>
                  <br>
                  <strong>Kangfu Mei</strong>, Aiwen Jiang, <a href="https://junchenglee.com/">Juncheng Li</a>, Mingwen Wang
                  <br>
                  <em>ACCV</em>, 2019
                  <br>
                  <a href="https://github.com/MKFMIKU/PFFNet">code</a> /
                  <a href="https://arxiv.org/abs/1810.02283">arXiv</a>
                  <p></p>
                  <p>PFFNet was the first dehazing netowrk that uses fully end-to-end neural network architecture without physical gating unit. More than <b>100 works</b> (untill 2024) adapot our strategy and show its effectiveness.</p>
                </td>
              </tr>
              
              <tr class="header">
                <td style="padding-left:20px; padding-top: 10px;width:25%vertical-align:middle">
                  <heading>2018</heading>
                  <hr class="solid">
                </td>
                <td style="width: 75%;"></td>
              </tr>

              <tr onmouseout="msrn_stop()" onmouseover="msrn_start()">
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='msrn_image'>
                      <img src='images/msrn_after.png' width="160">
                    </div>
                    <img src='images/msrn_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function msrn_start() {
                      document.getElementById('msrn_image').style.opacity = "1";
                    }

                    function msrn_stop() {
                      document.getElementById('msrn_image').style.opacity = "0";
                    }
                    msrn_stop()
                  </script>
                </td>
                <td style="padding-left:20px;padding-right:20px;padding-top:5px;width:75%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content_ECCV_2018/html/Juncheng_Li_Multi-scale_Residual_Network_ECCV_2018_paper.html">
                    <papertitle>Multi-scale Residual Network for Image Super-resolution</papertitle>
                  </a>
                  <br>
                  <a href="https://junchenglee.com/">Juncheng Li</a>, Faming Fang,
                  <strong>Kangfu Mei</strong>, Guixu Zhang
                  <br>
                  <em>ECCV</em>, 2018
                  <br>
                  <a href="https://github.com/MIVRC/MSRN-PyTorch">code</a> /
                  <a href="data/li2018multi.bib">bibtex</a>
                  <p></p>
                  <p>We built MSRN in 2018. It quickly becomes the foundamental component in all image restoration works and has more than <b>800 citations</b> untill 2024.</p>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Service</heading>
                  <p>Reviewer for CVPR, ICCV, ECCV, WACV, ICPR</p>
                  <p>Reviewer of International Journal of Computer Vision (IJCV)</p>
                  <p>Reviewer of IEEE Transactions on Image Processing (TIP)</p>
                  <p>Reviewer of IEEE Transactions on Multimedia (TMM)</p>
                  <p>Reviewer of IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</p>
                  <p>Reviewer of Computer Vision and Image Understanding (CVIU)</p>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Prizes</heading>
                  <p style="color: crimson">AIM2019 Mobile Raw to DSLR RGB Image Mapping Challenge (ICCV2019 Workshop):
                    Top 1</p>
                  <p>Alibaba Youku Video Enhancement and Super-Resolution Challenge 2019: Top 4</p>
                  <p>NTIRE2018 Image Dehazing Challenge (CVPR2018 Workshop): Honorable Mention Award & Top 6</p>
                  <p style="color: crimson">University Computer Software Programming Challenge 2018 in The Pearl River
                    Delta: Gold Award & Best innovative Award</p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
